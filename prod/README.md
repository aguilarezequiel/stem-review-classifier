# ðŸŽ® Steam Review Classifier

Clasificador de sentimiento de reseÃ±as de videojuegos de Steam usando **BERT** fine-tuneado.

## DescripciÃ³n

Este proyecto implementa un modelo de clasificaciÃ³n binaria (positiva/negativa) de reseÃ±as de videojuegos de Steam. Se realizÃ³ fine-tuning completo sobre el modelo `bert-base-uncased` de Hugging Face, entrenado con el dataset [Steam Reviews](https://www.kaggle.com/datasets/andrewmvd/steam-reviews) de Kaggle.

## TecnologÃ­as

- **Modelo**: BERT (bert-base-uncased) con fine-tuning completo
- **Framework**: PyTorch + Hugging Face Transformers
- **Interfaz**: Streamlit
- **Dataset**: Steam Reviews (~50,000 reseÃ±as balanceadas)

## Estructura del Proyecto

```
stem-review-classifier/
â”œâ”€â”€ data/                          # Datos y artefactos del entrenamiento
â”‚   â”œâ”€â”€ clean_reviews.csv          # Dataset limpio
â”‚   â”œâ”€â”€ tensors/                   # Datasets tokenizados (.pt)
â”‚   â”œâ”€â”€ model_save/                # Modelo guardado post-entrenamiento
â”‚   â””â”€â”€ results/                   # MÃ©tricas y grÃ¡ficos de evaluaciÃ³n
â”œâ”€â”€ dev/                           # Scripts de desarrollo (ejecuciÃ³n secuencial)
â”‚   â”œâ”€â”€ 01_download_and_clean.py   # Descarga y limpieza del dataset
â”‚   â”œâ”€â”€ 02_tokenize_and_dataset.py # TokenizaciÃ³n con BERT y creaciÃ³n del dataset PyTorch
â”‚   â”œâ”€â”€ 03_train_model.py          # Fine-tuning del modelo BERT
â”‚   â”œâ”€â”€ 04_evaluate_model.py       # EvaluaciÃ³n con mÃ©tricas y grÃ¡ficos
â”‚   â””â”€â”€ 05_export_model.py         # ExportaciÃ³n del modelo para producciÃ³n
â”œâ”€â”€ prod/                          # AplicaciÃ³n de producciÃ³n
â”‚   â”œâ”€â”€ app.py                     # AplicaciÃ³n Streamlit
â”‚   â”œâ”€â”€ utils.py                   # Funciones auxiliares
â”‚   â”œâ”€â”€ model_files/               # Modelo exportado (generado por 05_export)
â”‚   â”œâ”€â”€ requirements.txt           # Dependencias
â”‚   â””â”€â”€ README.md                  # Este archivo
```

## CÃ³mo Ejecutar

### 1. Entrenamiento (en `dev/`)

Ejecutar los scripts en orden desde la carpeta `dev/`:

```bash
cd dev

# Paso 1: Descargar y limpiar el dataset
python 01_download_and_clean.py

# Paso 2: Tokenizar y crear datasets PyTorch
python 02_tokenize_and_dataset.py

# Paso 3: Entrenar el modelo (fine-tuning de BERT)
python 03_train_model.py

# Paso 4: Evaluar el modelo
python 04_evaluate_model.py

# Paso 5: Exportar modelo para producciÃ³n
python 05_export_model.py
```

### 2. AplicaciÃ³n Web (en `prod/`)

```bash
cd prod
pip install -r requirements.txt
streamlit run app.py
```

## MetodologÃ­a

1. **Preprocesamiento**: Limpieza agresiva de texto (URLs, arte ASCII, caracteres especiales, spam) y balanceo de clases.
2. **TokenizaciÃ³n**: Usando `BertTokenizer.encode_plus()` con max_length=128, padding, truncation y attention masks.
3. **Fine-tuning**: Entrenamiento completo de todos los parÃ¡metros de `BertForSequenceClassification` con AdamW (lr=2e-5) y linear scheduler, 3 Ã©pocas, batch_size=32.
4. **EvaluaciÃ³n**: Accuracy, MCC (Matthews Correlation Coefficient), F1-score, matriz de confusiÃ³n y pruebas cualitativas.

## Trabajo PrÃ¡ctico Integrador

**Materia**: Redes Neuronales Profundas  
**Universidad**: UTN - Facultad Regional Mendoza
